{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://cocl.us/Data_Science_with_Scalla_top\"><img src = \"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/SC0103EN/adds/Data_Science_with_Scalla_notebook_top.png\" width = 750, align = \"center\"></a>\n",
    " <br/>\n",
    "<a><img src=\"https://ibm.box.com/shared/static/ugcqz6ohbvff804xp84y4kqnvvk3bq1g.png\" width=\"200\" align=\"center\"></a>\"\n",
    "\n",
    "# Linear Methods\n",
    "\n",
    "\n",
    "After completing this lesson you should be able to:\n",
    "\n",
    "* Understand the Pipeline API for Logistic Regression and Linear Least Squares\n",
    "* Perform classification with Logistic Regression\n",
    "* Perform regression with Linear Least Squares\n",
    "* Use regularization with Logistic Regression and Linear Least Squares\n",
    "\n",
    "## Logistic Regression\n",
    "\n",
    "* Widely used to predict binary responses\n",
    "* Can be generalized into multinomial logistic regression\n",
    "\n",
    "The benefits of Logistic Regression are:\n",
    "\n",
    "* there are no tuning parameters\n",
    "* the prediction equation is simple and easy to implement\n",
    "\n",
    "## Continuing from previous example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                   // Or use any other 2.x version here\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                     // Or use any other 2.x version here\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m org.apache.spark.SparkContext\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.log4j.{Level, Logger}\n",
       "\u001b[39m\n",
       "\u001b[36msc\u001b[39m: \u001b[32mSparkContext\u001b[39m = org.apache.spark.SparkContext@5633c0a7"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`org.apache.spark::spark-sql:2.4.0` // Or use any other 2.x version here\n",
    "import $ivy.`org.apache.spark::spark-mllib:2.4.0` // Or use any other 2.x version here\n",
    "import  org.apache.spark.SparkContext\n",
    "import org.apache.log4j.{Level, Logger}\n",
    "Logger.getLogger(\"org\").setLevel(Level.OFF)\n",
    "val sc= new SparkContext(\"local[*]\",\"Linear Methods\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.SparkSession\n",
       "\u001b[39m\n",
       "\u001b[36mspark\u001b[39m: \u001b[32mSparkSession\u001b[39m = org.apache.spark.sql.SparkSession@58d47eb\n",
       "\u001b[32mimport \u001b[39m\u001b[36mspark.implicits._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.functions._\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.mllib.util.MLUtils.{\n",
       "  convertVectorColumnsFromML => fromML,\n",
       "  convertVectorColumnsToML => toML\n",
       "}\u001b[39m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "val spark = SparkSession.builder().getOrCreate()\n",
    "import spark.implicits._\n",
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "import org.apache.spark.mllib.util.MLUtils.{\n",
    "  convertVectorColumnsFromML => fromML,\n",
    "  convertVectorColumnsToML => toML\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.mllib.util.MLUtils\n",
       " \n",
       "\u001b[39m\n",
       "\u001b[36mdata\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mDataset\u001b[39m[\u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mRow\u001b[39m] = [label: double, features: vector]\n",
       "\u001b[36msplitData\u001b[39m: \u001b[32mArray\u001b[39m[\u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mDataset\u001b[39m[\u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mRow\u001b[39m]] = \u001b[33mArray\u001b[39m(\n",
       "  [label: double, features: vector],\n",
       "  [label: double, features: vector]\n",
       ")\n",
       "\u001b[36mtrainingData\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mDataset\u001b[39m[\u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mRow\u001b[39m] = [label: double, features: vector]\n",
       "\u001b[36mtestData\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mDataset\u001b[39m[\u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mRow\u001b[39m] = [label: double, features: vector]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.mllib.util.MLUtils\n",
    " \n",
    "val data = toML(MLUtils.loadLibSVMFile(sc, \"data/sample_libsvm_data.txt\").toDF())\n",
    "\n",
    "val splitData = data.randomSplit(Array(0.7, 0.3))\n",
    "val trainingData = toML(splitData(0))\n",
    "val testData = toML(splitData(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19/12/19 13:49:29 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "19/12/19 13:49:29 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n",
      "19/12/19 13:49:30 INFO OWLQN: Step Size: 0.01044\n",
      "19/12/19 13:49:30 INFO OWLQN: Val and Grad Norm: 0.663665 (rel: 0.0235) 1.06655\n",
      "19/12/19 13:49:30 INFO OWLQN: Step Size: 1.000\n",
      "19/12/19 13:49:30 INFO OWLQN: Val and Grad Norm: 0.621545 (rel: 0.0635) 0.712942\n",
      "19/12/19 13:49:30 INFO OWLQN: Step Size: 1.000\n",
      "19/12/19 13:49:30 INFO OWLQN: Val and Grad Norm: 0.613702 (rel: 0.0126) 0.328140\n",
      "19/12/19 13:49:30 INFO OWLQN: Step Size: 1.000\n",
      "19/12/19 13:49:30 INFO OWLQN: Val and Grad Norm: 0.607013 (rel: 0.0109) 0.262894\n",
      "19/12/19 13:49:31 INFO OWLQN: Step Size: 1.000\n",
      "19/12/19 13:49:31 INFO OWLQN: Val and Grad Norm: 0.603494 (rel: 0.00580) 0.229197\n",
      "19/12/19 13:49:31 INFO OWLQN: Step Size: 1.000\n",
      "19/12/19 13:49:31 INFO OWLQN: Val and Grad Norm: 0.606208 (rel: -0.00448) 0.489577\n",
      "19/12/19 13:49:31 INFO OWLQN: Step Size: 0.5000\n",
      "19/12/19 13:49:31 INFO OWLQN: Val and Grad Norm: 0.598137 (rel: 0.0133) 0.167205\n",
      "19/12/19 13:49:31 INFO OWLQN: Step Size: 0.5000\n",
      "19/12/19 13:49:31 INFO OWLQN: Val and Grad Norm: 0.595877 (rel: 0.00378) 0.188475\n",
      "19/12/19 13:49:31 INFO OWLQN: Step Size: 0.5000\n",
      "19/12/19 13:49:31 INFO OWLQN: Val and Grad Norm: 0.594148 (rel: 0.00290) 0.0981238\n",
      "19/12/19 13:49:31 INFO OWLQN: Step Size: 1.000\n",
      "19/12/19 13:49:31 INFO OWLQN: Val and Grad Norm: 0.592412 (rel: 0.00292) 0.129815\n",
      "19/12/19 13:49:31 INFO OWLQN: Converged because max iterations reached\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: (692,[235,263,272,300,328,350,351,356,373,378,379,384,385,400,401,405,406,407,413,428,429,433,434,435,440,455,456,461,462,468,469,483,484,489,490,496,511,512,517,523,539,540,568],[-1.0986412082924127E-4,-1.632313565748736E-4,-7.820280286117048E-5,-1.8568940922179607E-4,-5.81762157320815E-5,7.691405301201737E-5,1.353341188408302E-4,-7.216976931811089E-6,-4.246742861080448E-5,2.2141292445093804E-4,1.9674226570246596E-4,-9.541445171391214E-6,-6.499288798183409E-5,-4.458420507627242E-5,-1.815671771401498E-5,1.0144572577371168E-4,7.811229595238786E-4,2.0547194260793074E-4,-1.3803675642766537E-4,-1.9355965274971758E-4,-4.202641730675044E-5,2.09045453328428E-4,8.660324841706133E-4,1.4636812501953356E-4,-7.230181731993262E-6,-1.3069469693037611E-4,-2.0564705368024763E-4,1.591693089228566E-4,8.12163993000338E-4,-1.5518801004015597E-5,-3.5693536582322817E-5,-1.3888957777080828E-4,-1.847595921522189E-4,1.6779482741926844E-4,1.5275296508028286E-4,-2.2478003321067003E-4,-3.694843494233926E-4,-3.420584877419159E-4,1.8164883454736233E-4,-4.558737431759475E-5,-4.3643299483185486E-4,-8.58825252426765E-4,-4.2269210155215873E-4])\n",
      "Intercept: 0.306953560096917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.ml.classification.LogisticRegression\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.ml.classification.BinaryLogisticRegressionSummary\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[36mlogr\u001b[39m: \u001b[32mLogisticRegression\u001b[39m = logreg_594e2e407cda\n",
       "\u001b[36mlogrModel\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32mml\u001b[39m.\u001b[32mclassification\u001b[39m.\u001b[32mLogisticRegressionModel\u001b[39m = LogisticRegressionModel: uid = logreg_594e2e407cda, numClasses = 2, numFeatures = 692"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import org.apache.spark.ml.classification.LogisticRegression\n",
    "import org.apache.spark.ml.classification.BinaryLogisticRegressionSummary\n",
    "\n",
    "val logr = new LogisticRegression().setMaxIter(10).setRegParam(0.3).setElasticNetParam(0.8)\n",
    "\n",
    "val logrModel = logr.fit(trainingData)\n",
    "\n",
    "println(s\"Weights: ${logrModel.coefficients}\\nIntercept: ${logrModel.intercept}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[D@4a20dd31\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mtrainingSummaryLR\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32mml\u001b[39m.\u001b[32mclassification\u001b[39m.\u001b[32mLogisticRegressionTrainingSummary\u001b[39m = org.apache.spark.ml.classification.BinaryLogisticRegressionTrainingSummaryImpl@1b58f332\n",
       "\u001b[36mobjectiveHistoryLR\u001b[39m: \u001b[32mArray\u001b[39m[\u001b[32mDouble\u001b[39m] = \u001b[33mArray\u001b[39m(\n",
       "  \u001b[32m0.6796085823169081\u001b[39m,\n",
       "  \u001b[32m0.6636648934036553\u001b[39m,\n",
       "  \u001b[32m0.6215449604522338\u001b[39m,\n",
       "  \u001b[32m0.6137017804540467\u001b[39m,\n",
       "  \u001b[32m0.607013086421216\u001b[39m,\n",
       "  \u001b[32m0.6034943216233379\u001b[39m,\n",
       "  \u001b[32m0.6062084997072426\u001b[39m,\n",
       "  \u001b[32m0.5981373286517916\u001b[39m,\n",
       "  \u001b[32m0.5958769145810525\u001b[39m,\n",
       "  \u001b[32m0.5941477681783172\u001b[39m,\n",
       "  \u001b[32m0.5924121616958908\u001b[39m\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val trainingSummaryLR = logrModel.summary\n",
    "val objectiveHistoryLR = trainingSummaryLR.objectiveHistory\n",
    "println(objectiveHistoryLR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Least Squares\n",
    "\n",
    "- Most common formulation for regression problems\n",
    "- Average loss = Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19/12/19 13:50:02 INFO OWLQN: Step Size: 0.005109\n",
      "19/12/19 13:50:02 INFO OWLQN: Val and Grad Norm: 0.469749 (rel: 0.0605) 1.76593\n",
      "19/12/19 13:50:02 INFO OWLQN: Step Size: 1.000\n",
      "19/12/19 13:50:02 INFO OWLQN: Val and Grad Norm: 0.440439 (rel: 0.0624) 1.07112\n",
      "19/12/19 13:50:02 INFO OWLQN: Step Size: 1.000\n",
      "19/12/19 13:50:02 INFO OWLQN: Val and Grad Norm: 0.433362 (rel: 0.0161) 0.749063\n",
      "19/12/19 13:50:02 INFO OWLQN: Step Size: 1.000\n",
      "19/12/19 13:50:02 INFO OWLQN: Val and Grad Norm: 0.427733 (rel: 0.0130) 1.39182\n",
      "19/12/19 13:50:02 INFO OWLQN: Step Size: 0.2500\n",
      "19/12/19 13:50:02 INFO OWLQN: Val and Grad Norm: 0.412539 (rel: 0.0355) 0.355665\n",
      "19/12/19 13:50:02 INFO OWLQN: Step Size: 0.5000\n",
      "19/12/19 13:50:02 INFO OWLQN: Val and Grad Norm: 0.410682 (rel: 0.00450) 0.595801\n",
      "19/12/19 13:50:02 INFO OWLQN: Step Size: 0.5000\n",
      "19/12/19 13:50:02 INFO OWLQN: Val and Grad Norm: 0.409360 (rel: 0.00322) 0.285346\n",
      "19/12/19 13:50:02 INFO OWLQN: Step Size: 0.5000\n",
      "19/12/19 13:50:02 INFO OWLQN: Val and Grad Norm: 0.408390 (rel: 0.00237) 0.554952\n",
      "19/12/19 13:50:02 INFO OWLQN: Step Size: 0.2500\n",
      "19/12/19 13:50:02 INFO OWLQN: Val and Grad Norm: 0.406352 (rel: 0.00499) 0.278863\n",
      "19/12/19 13:50:02 INFO OWLQN: Step Size: 1.000\n",
      "19/12/19 13:50:02 INFO OWLQN: Val and Grad Norm: 0.403621 (rel: 0.00672) 0.329384\n",
      "19/12/19 13:50:02 INFO OWLQN: Converged because max iterations reached\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-5.454051864433597E-7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-4.026886632749062E-6,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-2.72449774235545E-6,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-1.7008381720513028E-5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.2775982099686818E-5,0.0,0.0,0.0,0.0,-2.677267507841414E-6,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,4.0730086192587665E-5,8.101345117964779E-5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-2.102338093603794E-6,0.0,0.0,0.0,0.0,1.3377977573223918E-4,1.1704275913395652E-4,0.0,0.0,0.0,0.0,0.0,-3.87962025609083E-6,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-3.3736438746070193E-6,0.0,0.0,0.0,0.0,7.350898619427785E-5,1.4167934546538004E-4,1.2259857869623508E-4,0.0,0.0,0.0,0.0,0.0,-6.726188480432815E-6,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-1.8412815189571315E-5,-6.124248247418358E-7,0.0,0.0,0.0,1.2488425906842512E-4,1.987485199728834E-4,8.781049238801852E-5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-6.441683144163599E-6,-1.990205979286501E-5,0.0,0.0,0.0,0.0,1.0313728848452796E-4,1.4700338580064706E-4,-0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-6.40488116792174E-6,-1.7111859249221958E-5,0.0,0.0,0.0,0.0,1.0740045146277687E-4,9.03448127489246E-5,0.0,0.0,0.0,0.0,0.0,-1.826192745888421E-5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-3.626608720756904E-5,-2.1727704067903958E-5,0.0,0.0,0.0,0.0,1.1682499240413053E-4,0.0,0.0,0.0,0.0,0.0,-3.918001423273429E-7,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-6.497598500071445E-5,-1.0660865958023266E-4,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-2.165530899930409E-5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]\n",
      "Intercept: 0.3938524565227374\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.ml.regression.LinearRegression\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[36mlr\u001b[39m: \u001b[32mLinearRegression\u001b[39m = linReg_e6a7c19e4aee\n",
       "\u001b[36mlrModel\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32mml\u001b[39m.\u001b[32mregression\u001b[39m.\u001b[32mLinearRegressionModel\u001b[39m = linReg_e6a7c19e4aee"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.regression.LinearRegression\n",
    "\n",
    "val lr = new LinearRegression().setMaxIter(10).setRegParam(0.3).setElasticNetParam(0.8)\n",
    "\n",
    "val lrModel = lr.fit(trainingData)\n",
    "\n",
    "println(s\"Weights: ${lrModel.coefficients}\\nIntercept: ${lrModel.intercept}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[D@718e37c4\n",
      "+--------------------+\n",
      "|           residuals|\n",
      "+--------------------+\n",
      "| -0.3054057086542837|\n",
      "|-0.30997720733268874|\n",
      "|-0.32845177626009586|\n",
      "+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mtrainingSummaryLLS\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32mml\u001b[39m.\u001b[32mregression\u001b[39m.\u001b[32mLinearRegressionTrainingSummary\u001b[39m = org.apache.spark.ml.regression.LinearRegressionTrainingSummary@1cc0f870\n",
       "\u001b[36mobjectiveHistoryLLS\u001b[39m: \u001b[32mArray\u001b[39m[\u001b[32mDouble\u001b[39m] = \u001b[33mArray\u001b[39m(\n",
       "  \u001b[32m0.5\u001b[39m,\n",
       "  \u001b[32m0.4697491591306237\u001b[39m,\n",
       "  \u001b[32m0.4404392461736935\u001b[39m,\n",
       "  \u001b[32m0.43336243017102877\u001b[39m,\n",
       "  \u001b[32m0.42773346438265963\u001b[39m,\n",
       "  \u001b[32m0.4125393505063034\u001b[39m,\n",
       "  \u001b[32m0.4106821025206941\u001b[39m,\n",
       "  \u001b[32m0.4093600241924632\u001b[39m,\n",
       "  \u001b[32m0.4083902258773283\u001b[39m,\n",
       "  \u001b[32m0.4063523417368028\u001b[39m,\n",
       "  \u001b[32m0.40362144610608497\u001b[39m\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val trainingSummaryLLS = lrModel.summary\n",
    "val objectiveHistoryLLS = trainingSummaryLLS.objectiveHistory\n",
    "\n",
    "println(objectiveHistoryLLS)\n",
    "\n",
    "trainingSummaryLLS.residuals.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson Summary\n",
    "\n",
    "Having completed this lesson, you should be able to:\n",
    "\n",
    "- Understand the Pipelines API for Logistic Regression and Linear Least Squares\n",
    "- Perform classification with Logistic Regression\n",
    "- Perform classification with Linear Least Squares\n",
    "- Use regularization with Logistic Regression and Linear Least Squares\n",
    "\n",
    "### About the Authors\n",
    "\n",
    "[Petro Verkhogliad](https://www.linkedin.com/in/vpetro) is Consulting Manager at Lightbend. He holds a Masters degree in Computer Science with specialization in Intelligent Systems. He is passionate about functional programming and applications of AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.12.8",
   "language": "scala",
   "name": "scala_2_12_8"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
