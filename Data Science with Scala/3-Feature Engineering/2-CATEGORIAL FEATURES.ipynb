{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://cocl.us/Data_Science_with_Scalla_top\"><img src = \"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/SC0103EN/adds/Data_Science_with_Scalla_notebook_top.png\" width = 750, align = \"center\"></a>\n",
    " <br/>\n",
    "<a><img src=\"https://ibm.box.com/shared/static/ugcqz6ohbvff804xp84y4kqnvvk3bq1g.png\" width=\"200\" align=\"center\"></a>\"\n",
    "\n",
    "# Module 3: Feature Engineering - Categorical Features\n",
    "\n",
    "## Categorical Features\n",
    "\n",
    "### Lesson Objectives \n",
    "\n",
    "After completing this lesson, you should be able to: \n",
    "\n",
    "- encode categorical features with Spark's `StringIndexer`\n",
    "-\tencode categorical features with Spark's `OneHotEncoder`\n",
    "-\tknow how to use each of these Motivation \n",
    "-\tCategorical variables can take on only a limited number of possible values, like country, or gender\n",
    "-\tThey represent reality. You don't have infinite variation in between countries. You do have infinite values between two integers\n",
    "-\tCategories are less useful than integers for computations. So internally a computer will 'translate' categorical variables to integers\n",
    "\n",
    "\n",
    "### Motivation\n",
    "\n",
    "-\tIn R you have factors \n",
    "-\tIn python pandas you have the categorical data type. What is the equivalent structure in Spark?\n",
    "-\tThese structures usually map strings to integers in a way that makes future computations easier. In this video we will see how Spark does it\n",
    "\n",
    "\n",
    "### Why Are Integers Better?\n",
    "\n",
    "-\tSpark's classifiers and regressors only work with numerical features; string features must be converted to numbers a `StringIndexer`\n",
    "-\tThis helps keep Spark's internals simpler and more efficient\n",
    "-\tThere's little cost in transforming categorical features to numbers, and then back to strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                   // Or use any other 2.x version here\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                     // Or use any other 2.x version here\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m org.apache.spark.SparkContext\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.log4j.{Level, Logger}\n",
       "\u001b[39m\n",
       "\u001b[36msc\u001b[39m: \u001b[32mSparkContext\u001b[39m = org.apache.spark.SparkContext@12af23da"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`org.apache.spark::spark-sql:2.4.0` // Or use any other 2.x version here\n",
    "import $ivy.`org.apache.spark::spark-mllib:2.4.0` // Or use any other 2.x version here\n",
    "import  org.apache.spark.SparkContext\n",
    "import org.apache.log4j.{Level, Logger}\n",
    "Logger.getLogger(\"org\").setLevel(Level.OFF)\n",
    "val sc= new SparkContext(\"local[*]\",\"Categorical Features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.SparkSession\n",
       "\u001b[39m\n",
       "\u001b[36mspark\u001b[39m: \u001b[32mSparkSession\u001b[39m = org.apache.spark.sql.SparkSession@57b13e49\n",
       "\u001b[32mimport \u001b[39m\u001b[36mspark.implicits._\u001b[39m"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "val spark = SparkSession.builder().getOrCreate()\n",
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+\n",
      "| id|nationality|\n",
      "+---+-----------+\n",
      "|  0|         US|\n",
      "|  1|         UK|\n",
      "|  2|         FR|\n",
      "|  3|         US|\n",
      "|  4|         US|\n",
      "|  5|         FR|\n",
      "+---+-----------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mdf\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mpackage\u001b[39m.\u001b[32mDataFrame\u001b[39m = [id: int, nationality: string]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Using a StingIndexer\n",
    "\n",
    "val  df = spark.createDataFrame( Seq((0, \"US\"), (1, \"UK\"), (2, \"FR\"), (3, \"US\"), (4, \"US\"), (5, \"FR\") )).toDF(\"id\", \"nationality\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+------+\n",
      "| id|nationality|nIndex|\n",
      "+---+-----------+------+\n",
      "|  0|         US|   0.0|\n",
      "|  1|         UK|   2.0|\n",
      "|  2|         FR|   1.0|\n",
      "|  3|         US|   0.0|\n",
      "|  4|         US|   0.0|\n",
      "|  5|         FR|   1.0|\n",
      "+---+-----------+------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m org.apache.spark.ml.feature.StringIndexer\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[36mindexer\u001b[39m: \u001b[32mStringIndexer\u001b[39m = strIdx_fecaeffdd8a1\n",
       "\u001b[36mindexed\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mpackage\u001b[39m.\u001b[32mDataFrame\u001b[39m = [id: int, nationality: string ... 1 more field]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Understanding the Output of a StringIndexer\n",
    "import  org.apache.spark.ml.feature.StringIndexer\n",
    "\n",
    "val  indexer = new StringIndexer().setInputCol(\"nationality\").setOutputCol(\"nIndex\")\n",
    "val  indexed = indexer.fit(df).transform(df)\n",
    "indexed.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reversing the Mapping \n",
    "\n",
    "-\tThe classifiers in MLlib and spark.ml will predict numeric values that correspond to the index values\n",
    "-\t`IndexToString` is what you'll need to transform these numbers back into your original labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+\n",
      "|predictedIndex|predictedNationality|\n",
      "+--------------+--------------------+\n",
      "|           0.0|                  US|\n",
      "|           2.0|                  UK|\n",
      "|           1.0|                  FR|\n",
      "|           0.0|                  US|\n",
      "|           0.0|                  US|\n",
      "|           1.0|                  FR|\n",
      "+--------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m org.apache.spark.ml.feature.IndexToString\n",
       "\u001b[39m\n",
       "\u001b[36mconverter\u001b[39m: \u001b[32mIndexToString\u001b[39m = idxToStr_1fca5d97b968\n",
       "\u001b[36mpredictions\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mpackage\u001b[39m.\u001b[32mDataFrame\u001b[39m = [predictedIndex: double]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// IndexToString Example \n",
    "\n",
    "import  org.apache.spark.ml.feature.IndexToString\n",
    "val converter = new IndexToString().setInputCol(\"predictedIndex\").setOutputCol(\"predictedNationality\")\n",
    "val  predictions = indexed.selectExpr(\"nIndex as predictedIndex\")\n",
    "converter.transform(predictions).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OneHotEncoding\n",
    "\n",
    "-\tSuppose we are trying to fit a linear regressor that uses nationality as a feature\n",
    "-\tIt would be impossible to learn a weight for this one feature that can distinguish between the 3 nationalities in our dataset\n",
    "- It's better to instead have a separate Boolean feature for each nationality, and learn weights for those features independently\n",
    "\n",
    "\n",
    "### Spark's OneHotEncoder \n",
    "\n",
    "-\tThe `OneHotEncoder` creates a sparse vector column, with each dimension of this vector of Booleans representing one of the possible values of the original feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+------+-------------+\n",
      "| id|nationality|nIndex|      nVector|\n",
      "+---+-----------+------+-------------+\n",
      "|  0|         US|   0.0|(2,[0],[1.0])|\n",
      "|  1|         UK|   2.0|    (2,[],[])|\n",
      "|  2|         FR|   1.0|(2,[1],[1.0])|\n",
      "|  3|         US|   0.0|(2,[0],[1.0])|\n",
      "|  4|         US|   0.0|(2,[0],[1.0])|\n",
      "|  5|         FR|   1.0|(2,[1],[1.0])|\n",
      "+---+-----------+------+-------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m org.apache.spark.ml.feature.OneHotEncoder\n",
       "\u001b[39m\n",
       "\u001b[36mencoder\u001b[39m: \u001b[32mOneHotEncoder\u001b[39m = oneHot_06c9d6bdc282\n",
       "\u001b[36mencoded\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mpackage\u001b[39m.\u001b[32mDataFrame\u001b[39m = [id: int, nationality: string ... 2 more fields]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Using a OneHotEncoder \n",
    "import  org.apache.spark.ml.feature.OneHotEncoder\n",
    "val encoder = new OneHotEncoder().setInputCol(\"nIndex\").setOutputCol(\"nVector\")\n",
    "val  encoded = encoder.transform(indexed)\n",
    "encoded.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+------+-------------+\n",
      "| id|nationality|nIndex|      nVector|\n",
      "+---+-----------+------+-------------+\n",
      "|  0|         US|   0.0|(3,[0],[1.0])|\n",
      "|  1|         UK|   2.0|(3,[2],[1.0])|\n",
      "|  2|         FR|   1.0|(3,[1],[1.0])|\n",
      "|  3|         US|   0.0|(3,[0],[1.0])|\n",
      "|  4|         US|   0.0|(3,[0],[1.0])|\n",
      "|  5|         FR|   1.0|(3,[1],[1.0])|\n",
      "+---+-----------+------+-------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mencoder\u001b[39m: \u001b[32mOneHotEncoder\u001b[39m = oneHot_9341a58a979f\n",
       "\u001b[36mencoded\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mpackage\u001b[39m.\u001b[32mDataFrame\u001b[39m = [id: int, nationality: string ... 2 more fields]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// The dropLast Option\n",
    "\n",
    "val  encoder = new OneHotEncoder().setInputCol(\"nIndex\").\n",
    "setOutputCol(\"nVector\").setDropLast(false) \n",
    "\n",
    "val encoded = encoder.transform(indexed)\n",
    "encoded.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson Summary\n",
    "\n",
    "-\tHaving completed this lesson, you should now be able to:\n",
    "- encode categorical features with Spark's `StringIndexer`\n",
    "-\tencode categorical features with Spark's `OneHotEncoder` \n",
    "-\tknow when to use each of these\n",
    "\n",
    "### About the Authors\n",
    "\n",
    "[Petro Verkhogliad](https://www.linkedin.com/in/vpetro) is Consulting Manager at Lightbend. He holds a Masters degree in Computer Science with specialization in Intelligent Systems. He is passionate about functional programming and applications of AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.12.8",
   "language": "scala",
   "name": "scala_2_12_8"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
